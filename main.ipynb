{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRINH THE SON - 20127617"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import urllib.request\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "VARIANTS = {\n",
    "    \"100k\": {\"filename\": \"u.data\", \"sep\": \"\\t\"},\n",
    "    \"1m\": {\"filename\": \"ratings.dat\", \"sep\": r\"::\"},\n",
    "    \"20m\": {\"filename\": \"ratings.csv\", \"sep\": \",\"},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "variant = \"100k\"\n",
    "\n",
    "if variant not in VARIANTS:\n",
    "    raise ValueError(\n",
    "        f\"Invalid variant: {variant}. Valid options are {list(VARIANTS.keys())}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = f\"http://files.grouplens.org/datasets/movielens/ml-{variant}.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "variant_info = VARIANTS[variant]\n",
    "filename = variant_info[\"filename\"]\n",
    "dirname = f\"ml-{variant}\"\n",
    "zip_path = os.path.join(dirname + \".zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with urllib.request.urlopen(url) as r, open(zip_path, \"wb\") as f:\n",
    "    shutil.copyfileobj(r, f)\n",
    "with zipfile.ZipFile(zip_path, \"r\") as zf:\n",
    "    zf.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove zip file after extraction (optional)\n",
    "os.remove(zip_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = os.path.join(dirname, filename)\n",
    "names = [\"u_id\", \"i_id\", \"rating\", \"timestamp\"]\n",
    "dtype = {\"u_id\": np.uint32, \"i_id\": np.uint32, \"rating\": np.float64}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    csv_path,\n",
    "    names=names,\n",
    "    dtype=dtype,\n",
    "    header=0,\n",
    "    sep=VARIANTS[variant][\"sep\"],\n",
    ")\n",
    "\n",
    "df.sort_values(by=\"u_id\", inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df.sample(frac=0.8, random_state=7)\n",
    "val = df.drop(train.index.tolist()).sample(frac=0.5, random_state=8)\n",
    "test = df.drop(train.index.tolist()).drop(val.index.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVD:\n",
    "    def __init__(\n",
    "        self,\n",
    "        lr=0.005,\n",
    "        reg=0.02,\n",
    "        n_epochs=20,\n",
    "        n_factors=100,\n",
    "        early_stopping=False,\n",
    "        shuffle=False,\n",
    "        min_delta=0.001,\n",
    "        min_rating=1,\n",
    "        max_rating=5,\n",
    "    ):\n",
    "\n",
    "        self.lr = lr\n",
    "        self.reg = reg\n",
    "        self.n_epochs = n_epochs\n",
    "        self.n_factors = n_factors\n",
    "        self.early_stopping = early_stopping\n",
    "        self.shuffle = shuffle\n",
    "        self.min_delta = min_delta\n",
    "        self.min_rating = min_rating\n",
    "        self.max_rating = max_rating\n",
    "\n",
    "    def fit(self, X, X_val=None):\n",
    "        X = self._preprocess_data(X)\n",
    "\n",
    "        if X_val is not None:\n",
    "            X_val = self._preprocess_data(X_val, train=False, verbose=False)\n",
    "            self._init_metrics()\n",
    "\n",
    "        self.global_mean_ = np.mean(X[:, 2])\n",
    "        self._run_sgd(X, X_val)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def _preprocess_data(self, X, train=True, verbose=True):\n",
    "        print(\"Preprocessing data...\\n\")\n",
    "        X = X.copy()\n",
    "\n",
    "        if train:  # Mappings have to be created\n",
    "            user_ids = X[\"u_id\"].unique().tolist()\n",
    "            item_ids = X[\"i_id\"].unique().tolist()\n",
    "\n",
    "            n_users = len(user_ids)\n",
    "            n_items = len(item_ids)\n",
    "\n",
    "            user_idx = range(n_users)\n",
    "            item_idx = range(n_items)\n",
    "\n",
    "            self.user_mapping_ = dict(zip(user_ids, user_idx))\n",
    "            self.item_mapping_ = dict(zip(item_ids, item_idx))\n",
    "\n",
    "        X[\"u_id\"] = X[\"u_id\"].map(self.user_mapping_)\n",
    "        X[\"i_id\"] = X[\"i_id\"].map(self.item_mapping_)\n",
    "\n",
    "        # Tag validation set unknown users/items with -1 (enables\n",
    "        # `fast_methods._compute_val_metrics` detecting them)\n",
    "        X.fillna(-1, inplace=True)\n",
    "\n",
    "        X[\"u_id\"] = X[\"u_id\"].astype(np.int32)\n",
    "        X[\"i_id\"] = X[\"i_id\"].astype(np.int32)\n",
    "\n",
    "        return X[[\"u_id\", \"i_id\", \"rating\"]].values\n",
    "\n",
    "    def _init_metrics(self):\n",
    "        metrics = np.zeros((self.n_epochs, 3), dtype=float)\n",
    "        self.metrics_ = pd.DataFrame(metrics, columns=[\"Loss\", \"RMSE\", \"MAE\"])\n",
    "\n",
    "    def _run_sgd(self, X, X_val):\n",
    "        n_users = len(np.unique(X[:, 0]))\n",
    "        n_items = len(np.unique(X[:, 1]))\n",
    "\n",
    "        bu, bi, pu, qi = _initialization(n_users, n_items, self.n_factors)\n",
    "\n",
    "        # Run SGD\n",
    "        for epoch_ix in range(self.n_epochs):\n",
    "            start = self._on_epoch_begin(epoch_ix)\n",
    "\n",
    "            if self.shuffle:\n",
    "                X = _shuffle(X)\n",
    "\n",
    "            bu, bi, pu, qi = _run_epoch(\n",
    "                X, bu, bi, pu, qi, self.global_mean_, self.n_factors, self.lr, self.reg\n",
    "            )\n",
    "\n",
    "            if X_val is not None:\n",
    "                self.metrics_.loc[epoch_ix, :] = _compute_val_metrics(\n",
    "                    X_val, bu, bi, pu, qi, self.global_mean_, self.n_factors\n",
    "                )\n",
    "                self._on_epoch_end(\n",
    "                    start,\n",
    "                    self.metrics_.loc[epoch_ix, \"Loss\"],\n",
    "                    self.metrics_.loc[epoch_ix, \"RMSE\"],\n",
    "                    self.metrics_.loc[epoch_ix, \"MAE\"],\n",
    "                )\n",
    "\n",
    "                if self.early_stopping:\n",
    "                    val_rmse = self.metrics_[\"RMSE\"].tolist()\n",
    "                    if self._early_stopping(val_rmse, epoch_ix, self.min_delta):\n",
    "                        break\n",
    "\n",
    "            else:\n",
    "                self._on_epoch_end(start)\n",
    "\n",
    "        self.bu_ = bu\n",
    "        self.bi_ = bi\n",
    "        self.pu_ = pu\n",
    "        self.qi_ = qi\n",
    "\n",
    "    def predict(self, X, clip=True):\n",
    "        return [\n",
    "            self.predict_pair(u_id, i_id, clip)\n",
    "            for u_id, i_id in zip(X[\"u_id\"], X[\"i_id\"])\n",
    "        ]\n",
    "\n",
    "    def predict_pair(self, u_id, i_id, clip=True):\n",
    "        user_known, item_known = False, False\n",
    "        pred = self.global_mean_\n",
    "\n",
    "        if u_id in self.user_mapping_:\n",
    "            user_known = True\n",
    "            u_ix = self.user_mapping_[u_id]\n",
    "            pred += self.bu_[u_ix]\n",
    "\n",
    "        if i_id in self.item_mapping_:\n",
    "            item_known = True\n",
    "            i_ix = self.item_mapping_[i_id]\n",
    "            pred += self.bi_[i_ix]\n",
    "\n",
    "        if user_known and item_known:\n",
    "            pred += np.dot(self.pu_[u_ix], self.qi_[i_ix])\n",
    "\n",
    "        if clip:\n",
    "            pred = self.max_rating if pred > self.max_rating else pred\n",
    "            pred = self.min_rating if pred < self.min_rating else pred\n",
    "\n",
    "        return pred\n",
    "\n",
    "    def _early_stopping(self, val_rmse, epoch_idx, min_delta):\n",
    "        if epoch_idx > 0:\n",
    "            if val_rmse[epoch_idx] + min_delta > val_rmse[epoch_idx - 1]:\n",
    "                self.metrics_ = self.metrics_.loc[: (epoch_idx + 1), :]\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def _on_epoch_begin(self, epoch_ix):\n",
    "        start = time.time()\n",
    "        end = \"  | \" if epoch_ix < 9 else \" | \"\n",
    "        print(\"Epoch {}/{}\".format(epoch_ix + 1, self.n_epochs), end=end)\n",
    "\n",
    "        return start\n",
    "\n",
    "    def _on_epoch_end(self, start, val_loss=None, val_rmse=None, val_mae=None):\n",
    "        end = time.time()\n",
    "\n",
    "        if val_loss is not None:\n",
    "            print(f\"val_loss: {val_loss:.2f}\", end=\" - \")\n",
    "            print(f\"val_rmse: {val_rmse:.2f}\", end=\" - \")\n",
    "            print(f\"val_mae: {val_mae:.2f}\", end=\" - \")\n",
    "\n",
    "        print(f\"took {end - start:.1f} sec\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
